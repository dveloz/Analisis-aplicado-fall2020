{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "fbc3733bebacf1ca2f4fa31d8640f1270e10f16a1db3bd912b1c328029085d5f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import random as ran\n",
    "    \n",
    "\n",
    "\n",
    "class optimization:\n",
    "\n",
    "    def __init__ (self,fun, h):\n",
    "        self.fun = fun\n",
    "        self.h = h\n",
    "\n",
    "    def grad(self, x0):\n",
    "        n = len(x0)\n",
    "        G = np.zeros((n,1),dtype = float)\n",
    "        for i in range(n):\n",
    "            xh = np.array(x0, dtype = float)\n",
    "            xh[i,0] = xh[i,0] + self.h\n",
    "            G[i,0] = round((self.fun(xh)-self.fun(x0))/self.h,3) \n",
    "        return G\n",
    "\n",
    "    def hess(self, x0):\n",
    "        n = len(x0)\n",
    "        x0 = x0.reshape((n,))\n",
    "        s= (n,n)\n",
    "        H = np.zeros(s)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                z1 = np.zeros(n)\n",
    "                z2 = z1\n",
    "                z1[i] += self.h\n",
    "                z2[j] += self.h\n",
    "                x1 = x0 + z1 + z2\n",
    "                x2 = x0 + z1 - z2\n",
    "                x3 = x0 - z1 + z2\n",
    "                x4 = x0 - z1 - z2\n",
    "                H[i,j] = (self.fun(x1) - self.fun(x2) - self.fun(x3) + self.fun(x4))/(4*(self.h**2))\n",
    "        return H\n",
    "\n",
    "    def defpos(self,Bk):\n",
    "        return all(LA.eig(Bk)[0])>10e-2\n",
    "        \n",
    "\n",
    "    def mk(self,x0):\n",
    "        G = grad(x0, self.h)\n",
    "        H = hess(x0, self.h)\n",
    "        norma = np.linalg.norm(G)\n",
    "        p1 = -G/norma\n",
    "        p = np.transpose(p1)\n",
    "        mk = self.fun(x0) + p*G + 0.5*p*H*p1\n",
    "        return mk\n",
    "\n",
    "\n",
    "\n",
    "    def cholesky(self,Bk):      ##  modificador de la hessiana  \n",
    "        maxIt=100\n",
    "        beta = 10**-3\n",
    "        if np.min(np.diag(Bk)) > 10e-2 :           \n",
    "            factor = 0\n",
    "        else:\n",
    "            factor = -np.min(np.diag(Bk)) + beta\n",
    "        for i in range(maxIt):\n",
    "            Bk = Bk + factor*np.identity(len(Bk))\n",
    "            \n",
    "\n",
    "            if self.defpos(Bk):\n",
    "                return factor\n",
    "            else:\n",
    "                factor = np.max([beta,2*factor])\n",
    "        return factor\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def BLS(self, xk):         ##  Backtracking Line Search\n",
    "        a = 1\n",
    "        c =10e-4\n",
    "        pk = -np.linalg.inv(self.hess(xk)).dot(self.grad(xk))\n",
    "        iter = 1\n",
    "        while self.fun(xk +a*pk) > self.fun(xk) + c*a*np.dot(np.transpose(self.grad(xk)),pk) and iter<20:\n",
    "            a = a*.9\n",
    "            iter= iter +1\n",
    "            #print(iter)\n",
    "        return a\n",
    "\n",
    "    def newton(self,xk):\n",
    "        maxIt=100          \n",
    "        a = 1\n",
    "        for k in range(maxIt):\n",
    "            Bk = self.hess(xk)\n",
    "            pk = np.linalg.solve(Bk,-self.grad(xk)) \n",
    "            xk = xk + a*pk           \n",
    "            #print(k)\n",
    "        return xk\n",
    "\n",
    "    \n",
    "    def newton_whm(self,xk):          ## Newton with hessian modification\n",
    "        maxIt = 100\n",
    "        n = len(xk)\n",
    "        for k in range(maxIt):            \n",
    "            Bk = self.hess(xk)\n",
    "            \n",
    "            factor = self.cholesky(Bk)\n",
    "            Bk = self.hess(xk)+factor*np.identity(n)\n",
    "            pk = LA.solve(Bk, -self.grad(xk))\n",
    "            xk = xk + self.BLS(xk)*pk\n",
    "        return xk\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def BFGS(self,xk):      ##BFGS\n",
    "        tol = 10e-4\n",
    "        Bk = self.hess(xk)\n",
    "        Hk = LA.inv(Bk)\n",
    "        while LA.norm(self.grad(xk)) > tol:\n",
    "            gradf = self.grad(xk)\n",
    "            pk = -Hk.dot(gradf)\n",
    "            alpha = self.BLS(xk)\n",
    "            aux = xk.copy()\n",
    "            xk =  xk + alpha*pk\n",
    "            sk = -aux+xk.copy()\n",
    "            yk = self.grad(xk) - gradf\n",
    "            rho = 1/(np.dot(yk.T,sk))\n",
    "            U = np.identity(len(Hk))-(rho*sk).dot(np.transpose(yk))\n",
    "            Hk1 = U.dot(Hk).dot(np.transpose(U)) + (rho*sk).dot(np.transpose(sk))\n",
    "            x0 = xk\n",
    "            gf = self.grad(xk)\n",
    "            Hk = Hk1\n",
    "        return xk\n",
    "\n",
    "    def steepest_descent(self, x0):      ##Steepest descent en caso de que sea el ¡basic line search?\n",
    "        for i in range(100):\n",
    "            Bk = self.hess(x0)\n",
    "            pk = np.linalg.solve(Bk,-self.grad(x0))\n",
    "            x0 = x0 + self.BLS(x0)*pk\n",
    "            #print(i)\n",
    "        return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Función Rosenbrock\n",
      "\n",
      "El resultado obtenido mediante Steepest descent fue:\n",
      "[[  7.84388852]\n",
      " [-58.00614781]]\n",
      "\n",
      "El resultado obtenido con la busqueda lineal de Newton:\n",
      "[[   31.85621786]\n",
      " [-1049.62250702]]\n",
      "\n",
      "El resultado obtenido con la busqueda lineal de Newton modificada:\n",
      "[[  7.84388852]\n",
      " [-58.00614781]]\n",
      "\n",
      "El resultado obtenido con BFGS:\n",
      "[[0.9714118]\n",
      " [0.9435922]]\n"
     ]
    }
   ],
   "source": [
    "def Rosenbrock(x0):\n",
    "    x0= x0.reshape(2,)\n",
    "    a=1\n",
    "    b=100\n",
    "    x=x0[0]\n",
    "    y=x0[1]\n",
    "    f = (a-x)**2 + b*(y-x**2)**2\n",
    "    return f\n",
    "\n",
    "print(\"Función Rosenbrock\\n\")\n",
    "a = optimization(Rosenbrock, 10e-5)\n",
    "\n",
    "x0 = np.array([[3,2]]).T\n",
    "\n",
    "print(\"El resultado obtenido mediante Steepest descent fue:\")\n",
    "print(a.basicLineSearch(x0))\n",
    "print(\"\\nEl resultado obtenido con la busqueda lineal de Newton:\")\n",
    "print(a.newton(x0))\n",
    "print(\"\\nEl resultado obtenido con la busqueda lineal de Newton modificada:\")\n",
    "print(a.newton_whm(x0))\n",
    "print(\"\\nEl resultado obtenido con BFGS:\")\n",
    "print(a.BFGS(x0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Misma clase con parametros distintos para poder correr el problema en la base de datos###\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import random as ran\n",
    "    \n",
    "\n",
    "\n",
    "class optimization:\n",
    "\n",
    "    def __init__ (self,fun, h):\n",
    "        self.fun = fun\n",
    "        self.h = h\n",
    "\n",
    "    def grad(self, x0):     ##gradiente\n",
    "        n = len(x0)\n",
    "        G = np.zeros((n,1),dtype = float)\n",
    "        for i in range(n):\n",
    "            xh = np.array(x0, dtype = float)\n",
    "            xh[i,0] = xh[i,0] + self.h\n",
    "            G[i,0] = round((self.fun(xh)-self.fun(x0))/self.h,3) \n",
    "        return G\n",
    "\n",
    "    def hess(self, x0):     ##hessiana\n",
    "        n = len(x0)\n",
    "        x0 = x0.reshape((n,))\n",
    "        s= (n,n)\n",
    "        H = np.zeros(s)\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                z1 = np.zeros(n)\n",
    "                z2 = z1\n",
    "                z1[i] += self.h\n",
    "                z2[j] += self.h\n",
    "                x1 = x0 + z1 + z2\n",
    "                x2 = x0 + z1 - z2\n",
    "                x3 = x0 - z1 + z2\n",
    "                x4 = x0 - z1 - z2\n",
    "                H[i,j] = (self.fun(x1) - self.fun(x2) - self.fun(x3) + self.fun(x4))/(4*(self.h**2))\n",
    "        return H\n",
    "\n",
    "    def defpos(self,Bk):\n",
    "        return all(LA.eig(Bk)[0])>10e-1\n",
    "        \n",
    "\n",
    "    def mk(self,x0):\n",
    "        G = grad(x0, self.h)\n",
    "        H = hess(x0, self.h)\n",
    "        norma = np.linalg.norm(G)\n",
    "        p1 = -G/norma\n",
    "        p = np.transpose(p1)\n",
    "        mk = self.fun(x0) + p*G + 0.5*p*H*p1\n",
    "        return mk\n",
    "\n",
    "\n",
    "\n",
    "    def cholesky(self,Bk):      ##  modificador de la hessiana  \n",
    "        maxIt=100\n",
    "        beta = 10**-3\n",
    "        if np.min(np.diag(Bk)) > 10e-2 :           \n",
    "            factor = 0\n",
    "        else:\n",
    "            factor = -np.min(np.diag(Bk)) + beta\n",
    "        for i in range(maxIt):\n",
    "            Bk = Bk + factor*np.identity(len(Bk))\n",
    "            \n",
    "\n",
    "            if self.defpos(Bk):\n",
    "                return factor\n",
    "            else:\n",
    "                factor = np.max([beta,2*factor])\n",
    "        return factor\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    def BLS(self, xk):         ##Backtracking Line Search\n",
    "        a = 1\n",
    "        c =10e-4\n",
    "        try:\n",
    "            pk = -np.linalg.inv(self.hess(xk)).dot(self.grad(xk))\n",
    "        except:\n",
    "            return a\n",
    "        iter = 1\n",
    "        while self.fun(xk +a*pk) > self.fun(xk) + c*a*np.dot(np.transpose(self.grad(xk)),pk) and iter<20:\n",
    "            a = a*.9\n",
    "            iter= iter +1\n",
    "            #print(iter)\n",
    "        return a\n",
    "\n",
    "    def newton(self,xk):    ##Newton \n",
    "        maxIt=100          \n",
    "        a = 1\n",
    "        for k in range(maxIt):\n",
    "            Bk = self.hess(xk)\n",
    "            try:\n",
    "                pk = np.linalg.solve(Bk,-self.grad(xk)) \n",
    "            except:\n",
    "                return xk\n",
    "            xk = xk + a*pk           \n",
    "            #print(k)\n",
    "        return xk\n",
    "\n",
    "    \n",
    "    def newton_whm(self,xk):          ## Newton with hessian modification\n",
    "        maxIt = 100\n",
    "        n = len(xk)\n",
    "        for k in range(maxIt):            \n",
    "            Bk = self.hess(xk)\n",
    "            \n",
    "            factor = self.cholesky(Bk)\n",
    "            Bk = self.hess(xk)+factor*np.identity(n)\n",
    "            try:\n",
    "                pk = LA.solve(Bk, -self.grad(xk))\n",
    "            except:\n",
    "                return xk\n",
    "            xk = xk + self.BLS(xk)*pk\n",
    "        return xk\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    def BFGS(self,xk):          ##BFGS\n",
    "        tol = 10e-4\n",
    "        Bk = self.hess(xk)\n",
    "        Hk = LA.inv(Bk)\n",
    "        while LA.norm(self.grad(xk)) > tol:\n",
    "            gradf = self.grad(xk)\n",
    "            pk = -Hk.dot(gradf)\n",
    "            alpha = self.BLS(xk)\n",
    "            aux = xk.copy()\n",
    "            xk =  xk + alpha*pk\n",
    "            sk = -aux + xk.copy()\n",
    "            yk = self.grad(xk) - gradf\n",
    "            rho = 1/(np.dot(yk.T,sk))\n",
    "            U = np.identity(len(Hk))-(rho*sk).dot(np.transpose(yk))\n",
    "            Hk1 = U.dot(Hk).dot(np.transpose(U)) + (rho*sk).dot(np.transpose(sk))\n",
    "            x0 = xk\n",
    "            gf = self.grad(xk)\n",
    "            Hk = Hk1\n",
    "        return xk\n",
    "\n",
    "    def steepest_descent(self, x0):      ##Steepest descent: en caso de que este sea el ¿basic line search?\n",
    "        for i in range(100):\n",
    "            Bk = self.hess(x0)\n",
    "            try:\n",
    "                pk = np.linalg.solve(Bk,-self.grad(x0))\n",
    "            except:\n",
    "                return x0\n",
    "            x0 = x0 + self.BLS(x0)*pk\n",
    "            #print(i)\n",
    "        return x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Camaras (simplificado a 5 camaras y 300 crimenes)\n",
      "\n",
      "El resultado obtenido con BFGS:\n",
      "[[ 5.31291635e+10  4.68084121e+13]\n",
      " [ 5.32246950e+10 -4.66761752e+13]\n",
      " [ 5.27719747e+10 -5.41660074e+09]\n",
      " [-7.55383772e+10 -6.70312386e+10]\n",
      " [-7.39865713e+10 -7.11301117e+10]]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "file = open('crime_data.csv', 'r')\n",
    "file.readline()\n",
    "reader = csv.reader(file)\n",
    "crimes = []\n",
    "for crime in reader:\n",
    "    crimes.append(crime[3:5])\n",
    "camara_loc  = (np.random.rand(5,2) + [19, -100]).T\n",
    "crime_loc = np.array(crimes,dtype=\"float\")\n",
    "\n",
    "\n",
    "def fcosto(camara_loc):\n",
    "    camara_loc = camara_loc.reshape((5,2))\n",
    "    #print(camara_loc)\n",
    "\n",
    "    costo = 0\n",
    "    for i in range(len(camara_loc)):\n",
    "        for j in range(len(crime_loc)):\n",
    "            costo += np.sqrt((camara_loc[i][0]-crime_loc[j][0])**2+(camara_loc[i][1]-crime_loc[j][1])**2)\n",
    "        for k in range(len(camara_loc)):\n",
    "            if i!=k:\n",
    "                costo += 1/np.sqrt((camara_loc[i][0]-camara_loc[k][0])**2+(camara_loc[i][0]-camara_loc[k][0])**2)\n",
    "    return costo\n",
    "\n",
    "\n",
    "b = optimization(fcosto, 10e-5)\n",
    "\n",
    "x0 = camara_loc.reshape((10,1))\n",
    "\n",
    "print(\"Camaras (simplificado a 5 camaras y 300 crimenes)\")\n",
    "# print(\"El resultado obtenido mediante Steepest descent fue:\")\n",
    "# print(b.steepest_descent(x0))\n",
    "# print(\"\\nEl resultado obtenido con la busqueda lineal de Newton:\")\n",
    "# print(b.newton(x0).reshape((5,2)))\n",
    "# print(\"\\nEl resultado obtenido con la busqueda lineal de Newton modificada:\")\n",
    "# print(b.newton_whm(x0).reshape((5,2)))\n",
    "print(\"\\nEl resultado obtenido con BFGS:\")\n",
    "print(b.BFGS(x0).reshape((5,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}